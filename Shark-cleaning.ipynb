{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shark attacks data cleaning\n",
    "\n",
    "## ¿Los tiburones blancos prefieren la carne de un surfista o un buceador?\n",
    "\n",
    "En este proyecto se busca dar una vuelta irónica a la información recopilada de ataques de tiburones a personas, con el fin de buscar las preferencias de los tiburones a la hora de comer.\n",
    "\n",
    "Para ello se realizarán distintos métodos de limpieza de datos y aplicación de filtros para ver nuestros resultados.\n",
    "\n",
    "- Importación de las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Src.SharkFn as Fn\n",
    "\n",
    "#Ver el archivo .py para saber qué hace cada función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creación del data frame Madre\n",
    "Se crea únicamente con la finalidad de tener un backup, y hacer una primera exploración sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Madre = pd.read_csv('Input/GSAF5.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area',\n",
       "       'Location', 'Activity', 'Name', 'Sex ', 'Age', 'Injury',\n",
       "       'Fatal (Y/N)', 'Time', 'Species ', 'Investigator or Source', 'pdf',\n",
       "       'href formula', 'href', 'Case Number.1', 'Case Number.2',\n",
       "       'original order', 'Unnamed: 22', 'Unnamed: 23'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Madre.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5992, 24)\n"
     ]
    }
   ],
   "source": [
    "print (df_Madre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                     43\n",
       "Area                       402\n",
       "Location                   496\n",
       "Activity                   527\n",
       "Name                       200\n",
       "Sex                        567\n",
       "Age                       2681\n",
       "Injury                      27\n",
       "Fatal (Y/N)                 19\n",
       "Time                      3213\n",
       "Species                   2934\n",
       "Investigator or Source      15\n",
       "href formula                 1\n",
       "href                         3\n",
       "Unnamed: 22               5991\n",
       "Unnamed: 23               5990\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = df_Madre.isnull().sum()\n",
    "null_cols\n",
    "null_cols[null_cols > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado iba viendo una a una los diferentes valores de las columnas, para ver qué me podía encontrar.\n",
    "\n",
    "Además clasifiqué las columnas en las que podía limpar pero con esfuerzo, las facilmente limpiables y las que no tocaría ni con un palo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza pero con esfuerzo:\n",
    "# set(df_Madre['Activity'])\n",
    "# set(df_Madre['Time'])\n",
    "# set(df_Madre['Species '])\n",
    "# set(df_Madre['Country'])\n",
    "\n",
    "# Facilmente limpiables:\n",
    "# print(df_Madre['Type'].value_counts())\n",
    "# print(df_Madre['Sex '].value_counts())\n",
    "# print(df_Madre['Fatal (Y/N)'].value_counts())\n",
    "\n",
    "# Seguro que te quieres meter a analizar y comparar estos pares??\n",
    "# set(df_Madre['Date'])\n",
    "# set(df_Madre['Year'])\n",
    "\n",
    "# set(df_Madre['Area'])\n",
    "# set(df_Madre['Location'])\n",
    "\n",
    "# set(df_Madre['Name'])\n",
    "# set(df_Madre['Age'])\n",
    "# set(df_Madre['Injury'])\n",
    "\n",
    "    #-----------#\n",
    "    # ERROR 404: NO TIME FOUND TO FIX THIS:\n",
    "        # set(df_Madre['Case Number'])\n",
    "        # set(df_Madre['Investigator or Source'])\n",
    "        # set(df_Madre['pdf'])\n",
    "        # set(df_Madre['href formula'])\n",
    "        # set(df_Madre['href'])\n",
    "        # set(df_Madre['Case Number.1'])\n",
    "        # set(df_Madre['Case Number.2'])\n",
    "        # set(df_Madre['original order'])\n",
    "        # set(df_Madre['Unnamed: 22'])\n",
    "        # set(df_Madre['Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez elegidas las posibles columnas a retocar, elimino las que no voy a tocar ni por asomo, y posteriormente arreglo algunos títulos de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Case Number', 'Date', 'Year', 'Area', 'Location', 'Name',\n",
    "           'Age', 'Injury','Investigator or Source','pdf','href formula','href',\n",
    "           'Case Number.1','Case Number.2','original order','Unnamed: 22','Unnamed: 23']\n",
    "df_raw = df_Madre\n",
    "df_raw.drop(to_drop, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Type', 'Country', 'Activity', 'Sex', 'Fatal', 'Time', 'Species'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.rename(columns = {'Species ': 'Species',\n",
    "                        'Sex ': 'Sex',\n",
    "                        'Fatal (Y/N)' : 'Fatal'}, inplace=True)\n",
    "df_raw.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando Sex:\n",
    "Al final no utilicé esta columna, pero me gustaría implementarla en un futuro, por eso la dejo aquí.\n",
    "- Me gustaría añadir una condición para rellenar esos NaN que fuera por porcentaje de las actuales víctimas\n",
    "- M = 0.89 y F = 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M      4837\n",
       "F       585\n",
       "NaN     570\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.Sex = Fn.clean_last_ws(df_raw.Sex.str)\n",
    "\n",
    "df_raw.loc[(df_raw.Sex == '.')|\n",
    "           (df_raw.Sex == 'N')|\n",
    "           (df_raw.Sex == 'lli'), 'Sex'] = np.nan\n",
    "\n",
    "df_raw.Sex.value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando Fatal:\n",
    "Al igual que la anterior, final no utilicé esta columna, pero me gustaría implementarla en un futuro, por eso la dejo aquí.\n",
    "- En este caso los NaN los metería en que sí han sido fatales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    4325\n",
       "Y    1667\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.Fatal = Fn.clean_first_ws(df_raw.Fatal.str)\n",
    "df_raw.Fatal = Fn.clean_last_ws(df_raw.Fatal.str)\n",
    "df_raw.Fatal = df_raw.Fatal.str.capitalize()\n",
    "\n",
    "df_raw.loc[(df_raw.Fatal == '#value!')|\n",
    "           (df_raw.Fatal == 'F')|\n",
    "           (df_raw.Fatal == 'Unknown'), 'Fatal'] = np.nan\n",
    "\n",
    "df_raw.Fatal.fillna('Y', inplace = True)\n",
    "\n",
    "df_raw.Fatal.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando Species:\n",
    "\n",
    "En primer lugar quién me manda meterme en esta columna pensando que iba a sacar oro de ella...\n",
    "Pero bueno, lo primero que hago es una limpieza general de cosas raras que puede haber dentro de cada valor, e iba viendo poco a poco cómo iba quedando.\n",
    "\n",
    "(Ver el archivo .py para saber qué hace cada función)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.Species = Fn.clean_weird_ch(df_raw.Species.str)\n",
    "df_raw.Species = Fn.clean_1to2_ch(df_raw.Species.str)\n",
    "df_raw.Species = Fn.clean_num(df_raw.Species.str)\n",
    "df_raw.Species = Fn.clean_mult_ws(df_raw.Species.str)\n",
    "df_raw.Species = Fn.clean_last_ws(df_raw.Species.str)\n",
    "df_raw.Species = Fn.clean_first_ws(df_raw.Species.str)\n",
    "\n",
    "# set(df_raw['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Bueno aquí es donde la matan\" - Boyander \n",
    "\n",
    "- En primer lugar me di cuenta de que había algunas entradas vacías o se habían quedado vacías después de la limpia y les asigné el valor NaN con la función np.nan\n",
    "\n",
    "\n",
    "- Posteriormente todos los NaN los sustituyo por \"shark\" ya que si están registrados, aunque no pertenezcan a una serie en concreto, serán tiburones, y además pasé todos los caracteres a minúscula.\n",
    "\n",
    "\n",
    "- Despúes hice un .findall haciendo uso de la \"complejidad\" del idioma de Shakespeare, sabiendo que la raza del tiburón iría precedida de \"shark\".\n",
    "\n",
    "\n",
    "- Pasé el resultado del .findall, definiendo en el camino el tipo \"undef.\"\n",
    "\n",
    "\n",
    "- Finalmente hago una agrupación de los nombres para referirse a la misma especie de tiburón (buscando en Wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undef. shark        4446\n",
       "white shark          614\n",
       "tiger shark          259\n",
       "bull shark           197\n",
       "nurse shark          157\n",
       "copper shark          91\n",
       "reef shark            67\n",
       "blacktip shark        64\n",
       "mako shark            53\n",
       "hammerhead shark      44\n",
       "Name: Shark_sp, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.loc[(df_raw.Species == ''), 'Species'] = np.nan\n",
    "\n",
    "df_raw.Species.fillna('shark', inplace = True)\n",
    "df_raw.Species = df_raw.Species.str.lower()\n",
    "\n",
    "df_raw.Species = df_raw.Species.str.findall(r\"\\w+\\sshark\")\n",
    "\n",
    "lst_cc_sp = []\n",
    "for e in df_raw.Species:\n",
    "    if e == []:\n",
    "        lst_cc_sp.append(\"undef. shark\")\n",
    "    else:\n",
    "        lst_cc_sp.append(e[0])\n",
    "\n",
    "df_raw[\"Shark_sp\"] = lst_cc_sp\n",
    "# df_raw.Shark_sp.value_counts()\n",
    "\n",
    "df_raw.loc[(df_raw.Shark_sp == 'bonito shark'), 'Shark_sp'] = \"mako shark\"\n",
    "\n",
    "df_raw.loc[(df_raw.Shark_sp == 'sandtiger shark')|\n",
    "           (df_raw.Shark_sp == 'raggedtooth shark'), 'Shark_sp'] = \"nurse shark\"\n",
    "\n",
    "df_raw.loc[(df_raw.Shark_sp == 'zambesi shark'), 'Shark_sp'] = \"bull shark\"\n",
    "\n",
    "df_raw.loc[(df_raw.Shark_sp == 'whitetip shark')|\n",
    "           (df_raw.Shark_sp == 'whaler shark'), 'Shark_sp'] = \"copper shark\"\n",
    "\n",
    "df_raw.loc[(df_raw.Shark_sp != 'white shark')&\n",
    "           (df_raw.Shark_sp != 'tiger shark')&\n",
    "           (df_raw.Shark_sp != 'bull shark')&\n",
    "           (df_raw.Shark_sp != 'nurse shark')&\n",
    "           (df_raw.Shark_sp != 'copper shark')&\n",
    "           (df_raw.Shark_sp != 'reef shark')&\n",
    "           (df_raw.Shark_sp != 'blacktip shark')&\n",
    "           (df_raw.Shark_sp != 'mako shark')&\n",
    "           (df_raw.Shark_sp != 'hammerhead shark'), 'Shark_sp'] = \"undef. shark\"\n",
    "\n",
    "\n",
    "df_raw.Shark_sp.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando Activity:\n",
    "\n",
    "Aquí más de lo mismo que arriba solo que para detectar el tipo de actividad, de nuevo me basé en la \"complejidad\" del lenguaje de Shakespeare, sabiendo que el tipo de la actividad vendría dado por la terminación en \"-ing\" como el Banco. (Y sí también busqué los terminados en -ed pero no eran suficientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "swimming      1430\n",
       "undef. act    1238\n",
       "surfing       1198\n",
       "fishing       1105\n",
       "diving         622\n",
       "sailing        399\n",
       "Name: Deadly_act, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.Activity.fillna('undefing', inplace = True)\n",
    "df_raw.Activity = df_raw.Activity.str.lower()\n",
    "\n",
    "df_raw.Activity = df_raw.Activity.str.findall(r\"\\w+ing\")\n",
    "\n",
    "# df_raw.Activity\n",
    "\n",
    "lst_cc_act = []\n",
    "for e in df_raw.Activity:\n",
    "    if e == []:\n",
    "        lst_cc_act.append(\"undef. act\")\n",
    "    else:\n",
    "        lst_cc_act.append(e[0])\n",
    "\n",
    "df_raw[\"Deadly_act\"] = lst_cc_act\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'spearfishing')|\n",
    "           (df_raw.Deadly_act == 'collecting')|\n",
    "           (df_raw.Deadly_act == 'netting'), 'Deadly_act'] = \"fishing\"\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'bathing')|\n",
    "           (df_raw.Deadly_act == 'lifesaving')|\n",
    "           (df_raw.Deadly_act == 'attempting')|\n",
    "           (df_raw.Deadly_act == 'splashing')|\n",
    "           (df_raw.Deadly_act == 'wading'), 'Deadly_act'] = \"swimming\"\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'snorkeling')|\n",
    "           (df_raw.Deadly_act == 'skindiving')|\n",
    "           (df_raw.Deadly_act == 'filming')|\n",
    "           (df_raw.Deadly_act == 'freediving'), 'Deadly_act'] = \"diving\"\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'standing')|\n",
    "           (df_raw.Deadly_act == 'floating')|\n",
    "           (df_raw.Deadly_act == 'treading')|\n",
    "           (df_raw.Deadly_act == 'walking')|\n",
    "           (df_raw.Deadly_act == 'sinking')|\n",
    "           (df_raw.Deadly_act == 'boating')|\n",
    "           (df_raw.Deadly_act == 'boarding'), 'Deadly_act'] = \"sailing\"\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'kayaking')|\n",
    "           (df_raw.Deadly_act == 'skiing')|\n",
    "           (df_raw.Deadly_act == 'playing')|\n",
    "           (df_raw.Deadly_act == 'canoeing')|\n",
    "           (df_raw.Deadly_act == 'windsurfing')|\n",
    "           (df_raw.Deadly_act == 'rowing')|\n",
    "           (df_raw.Deadly_act == 'paddling')|\n",
    "           (df_raw.Deadly_act == 'sitting'), 'Deadly_act'] = \"surfing\"\n",
    "\n",
    "df_raw.loc[(df_raw.Deadly_act == 'undefing')|\n",
    "           ((df_raw.Deadly_act != 'fishing')&\n",
    "            (df_raw.Deadly_act != 'diving')&\n",
    "            (df_raw.Deadly_act != 'sailing')&\n",
    "            (df_raw.Deadly_act != 'surfing')&\n",
    "           (df_raw.Deadly_act != 'swimming')), 'Deadly_act'] = \"undef. act\"\n",
    "\n",
    "\n",
    "df_raw.Deadly_act.value_counts().head(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se agrupa todo de forma coherente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shark_sp      Deadly_act\n",
       "bull shark    swimming      0.319797\n",
       "              fishing       0.248731\n",
       "              surfing       0.167513\n",
       "              undef. act    0.111675\n",
       "              sailing       0.086294\n",
       "              diving        0.065990\n",
       "copper shark  fishing       0.307692\n",
       "              surfing       0.241758\n",
       "              diving        0.186813\n",
       "              swimming      0.120879\n",
       "              undef. act    0.109890\n",
       "              sailing       0.032967\n",
       "nurse shark   fishing       0.331210\n",
       "              diving        0.197452\n",
       "              undef. act    0.171975\n",
       "              swimming      0.159236\n",
       "              surfing       0.121019\n",
       "              sailing       0.019108\n",
       "tiger shark   surfing       0.262548\n",
       "              fishing       0.177606\n",
       "              swimming      0.169884\n",
       "              diving        0.154440\n",
       "              undef. act    0.135135\n",
       "              sailing       0.100386\n",
       "undef. shark  swimming      0.264732\n",
       "              undef. act    0.238417\n",
       "              surfing       0.184435\n",
       "              fishing       0.160369\n",
       "              diving        0.085245\n",
       "              sailing       0.066802\n",
       "white shark   surfing       0.327362\n",
       "              fishing       0.214984\n",
       "              diving        0.179153\n",
       "              swimming      0.127036\n",
       "              undef. act    0.086319\n",
       "              sailing       0.065147\n",
       "Name: Deadly_act, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_shark = [\"white shark\", \"tiger shark\", \"bull shark\", \"nurse shark\", \"copper shark\", \"undef. shark\"]\n",
    "lst_act = [\"swimming\", \"surfing\", \"fishing\", \"diving\", \"sailing\"]\n",
    "\n",
    "df_new = df_raw.loc[ df_raw.Shark_sp.isin(lst_shark), ['Shark_sp', 'Deadly_act'] ]\n",
    "\n",
    "df_new.groupby('Shark_sp').Deadly_act.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado final:\n",
    "\n",
    "## Los tiburones blancos prefieren surfistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
